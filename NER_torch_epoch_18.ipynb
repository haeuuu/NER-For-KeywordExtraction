{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "0803 NER 학습시키기-pytorch(n+s, epoch 18).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8c56b8626fe7438d8af186392d0ca0f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_97b386a45bba47e58e57a06733102bf7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_20f91b582e5148babf5348b59ade59ee",
              "IPY_MODEL_0901c3216eff426c8ab214dde6de2e06"
            ]
          }
        },
        "97b386a45bba47e58e57a06733102bf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20f91b582e5148babf5348b59ade59ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8c0511798dbc4c84b9108ee5780fbfea",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 371391,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 371391,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_289c937e54054d92abbbd1c9b1c9aeb5"
          }
        },
        "0901c3216eff426c8ab214dde6de2e06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_baf6c5ccbb53471781dc84acc7279bcd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 371k/371k [00:23&lt;00:00, 16.1kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_708609714f744e118de7d853e0925909"
          }
        },
        "8c0511798dbc4c84b9108ee5780fbfea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "289c937e54054d92abbbd1c9b1c9aeb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "baf6c5ccbb53471781dc84acc7279bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "708609714f744e118de7d853e0925909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14fdbeef1b8a4a04aa28140b01a93255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_374e26941bb347589ed980e268fe746d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ea4dccb4bb2c4687af071134da64c60a",
              "IPY_MODEL_c7a8e850d3ad4a27abdafd5d1cac28b7"
            ]
          }
        },
        "374e26941bb347589ed980e268fe746d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea4dccb4bb2c4687af071134da64c60a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_afd048cf0b604886acc97044eb14f2f7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 77779,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 77779,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_64dd85adbeb142bd9be04a4a817bb033"
          }
        },
        "c7a8e850d3ad4a27abdafd5d1cac28b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c97ec6d52db543dcb5856b91835c7197",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 77.8k/77.8k [00:20&lt;00:00, 3.77kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_903ab9c69d6f434bae3396df6ab51156"
          }
        },
        "afd048cf0b604886acc97044eb14f2f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "64dd85adbeb142bd9be04a4a817bb033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c97ec6d52db543dcb5856b91835c7197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "903ab9c69d6f434bae3396df6ab51156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5q539G8T9z1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "f79180f1-9519-4c08-85c4-c744cb049d34"
      },
      "source": [
        "!pip install pytorch-crf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-crf\n",
            "  Downloading https://files.pythonhosted.org/packages/96/7d/4c4688e26ea015fc118a0327e5726e6596836abce9182d3738be8ec2e32a/pytorch_crf-0.7.2-py3-none-any.whl\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INK0TgcBUDqU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "4d774d07-52fc-4eee-9247-7327605cc1a3"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 24.4MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 16.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 31.0MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 28.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=b1e412c69e155df18afd214c1fdb70d97558def1e580885f51baf1a9550c0e98\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-YLQYvMT5U7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2196fc1c-700b-4750-ddf8-78e9fd5d6ae6"
      },
      "source": [
        "from transformers import *\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "import pandas as pd\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torchcrf import CRF\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5zIfpDaT5VS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "import os\n",
        "import unicodedata\n",
        "from shutil import copyfile\n",
        "\n",
        "from transformers import PreTrainedTokenizer\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "VOCAB_FILES_NAMES = {\"vocab_file\": \"tokenizer_78b3253a26.model\",\n",
        "                     \"vocab_txt\": \"vocab.txt\"}\n",
        "\n",
        "PRETRAINED_VOCAB_FILES_MAP = {\n",
        "    \"vocab_file\": {\n",
        "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\",\n",
        "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/tokenizer_78b3253a26.model\",\n",
        "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/tokenizer_78b3253a26.model\"\n",
        "    },\n",
        "    \"vocab_txt\": {\n",
        "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\",\n",
        "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/vocab.txt\",\n",
        "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/vocab.txt\"\n",
        "    }\n",
        "}\n",
        "\n",
        "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\n",
        "    \"monologg/kobert\": 512,\n",
        "    \"monologg/kobert-lm\": 512,\n",
        "    \"monologg/distilkobert\": 512\n",
        "}\n",
        "\n",
        "PRETRAINED_INIT_CONFIGURATION = {\n",
        "    \"monologg/kobert\": {\"do_lower_case\": False},\n",
        "    \"monologg/kobert-lm\": {\"do_lower_case\": False},\n",
        "    \"monologg/distilkobert\": {\"do_lower_case\": False}\n",
        "}\n",
        "\n",
        "SPIECE_UNDERLINE = u'▁'\n",
        "\n",
        "\n",
        "class KoBertTokenizer(PreTrainedTokenizer):\n",
        "    \"\"\"\n",
        "        SentencePiece based tokenizer. Peculiarities:\n",
        "            - requires `SentencePiece <https://github.com/google/sentencepiece>`_\n",
        "    \"\"\"\n",
        "    vocab_files_names = VOCAB_FILES_NAMES\n",
        "    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\n",
        "    pretrained_init_configuration = PRETRAINED_INIT_CONFIGURATION\n",
        "    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            vocab_file,\n",
        "            vocab_txt,\n",
        "            do_lower_case=False,\n",
        "            remove_space=True,\n",
        "            keep_accents=False,\n",
        "            unk_token=\"[UNK]\",\n",
        "            sep_token=\"[SEP]\",\n",
        "            pad_token=\"[PAD]\",\n",
        "            cls_token=\"[CLS]\",\n",
        "            mask_token=\"[MASK]\",\n",
        "            **kwargs):\n",
        "        super().__init__(\n",
        "            unk_token=unk_token,\n",
        "            sep_token=sep_token,\n",
        "            pad_token=pad_token,\n",
        "            cls_token=cls_token,\n",
        "            mask_token=mask_token,\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "        # Build vocab\n",
        "        self.token2idx = dict()\n",
        "        self.idx2token = []\n",
        "        with open(vocab_txt, 'r', encoding='utf-8') as f:\n",
        "            for idx, token in enumerate(f):\n",
        "                token = token.strip()\n",
        "                self.token2idx[token] = idx\n",
        "                self.idx2token.append(token)\n",
        "\n",
        "        try:\n",
        "            import sentencepiece as spm\n",
        "        except ImportError:\n",
        "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n",
        "                           \"pip install sentencepiece\")\n",
        "\n",
        "        self.do_lower_case = do_lower_case\n",
        "        self.remove_space = remove_space\n",
        "        self.keep_accents = keep_accents\n",
        "        self.vocab_file = vocab_file\n",
        "        self.vocab_txt = vocab_txt\n",
        "\n",
        "        self.sp_model = spm.SentencePieceProcessor()\n",
        "        self.sp_model.Load(vocab_file)\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return len(self.idx2token)\n",
        "\n",
        "    def get_vocab(self):\n",
        "        return dict(self.token2idx, **self.added_tokens_encoder)\n",
        "\n",
        "    def __getstate__(self):\n",
        "        state = self.__dict__.copy()\n",
        "        state[\"sp_model\"] = None\n",
        "        return state\n",
        "\n",
        "    def __setstate__(self, d):\n",
        "        self.__dict__ = d\n",
        "        try:\n",
        "            import sentencepiece as spm\n",
        "        except ImportError:\n",
        "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n",
        "                           \"pip install sentencepiece\")\n",
        "        self.sp_model = spm.SentencePieceProcessor()\n",
        "        self.sp_model.Load(self.vocab_file)\n",
        "\n",
        "    def preprocess_text(self, inputs):\n",
        "        if self.remove_space:\n",
        "            outputs = \" \".join(inputs.strip().split())\n",
        "        else:\n",
        "            outputs = inputs\n",
        "        outputs = outputs.replace(\"``\", '\"').replace(\"''\", '\"')\n",
        "\n",
        "        if not self.keep_accents:\n",
        "            outputs = unicodedata.normalize('NFKD', outputs)\n",
        "            outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\n",
        "        if self.do_lower_case:\n",
        "            outputs = outputs.lower()\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def _tokenize(self, text, return_unicode=True, sample=False):\n",
        "        \"\"\" Tokenize a string. \"\"\"\n",
        "        text = self.preprocess_text(text)\n",
        "\n",
        "        if not sample:\n",
        "            pieces = self.sp_model.EncodeAsPieces(text)\n",
        "        else:\n",
        "            pieces = self.sp_model.SampleEncodeAsPieces(text, 64, 0.1)\n",
        "        new_pieces = []\n",
        "        for piece in pieces:\n",
        "            if len(piece) > 1 and piece[-1] == str(\",\") and piece[-2].isdigit():\n",
        "                cur_pieces = self.sp_model.EncodeAsPieces(piece[:-1].replace(SPIECE_UNDERLINE, \"\"))\n",
        "                if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\n",
        "                    if len(cur_pieces[0]) == 1:\n",
        "                        cur_pieces = cur_pieces[1:]\n",
        "                    else:\n",
        "                        cur_pieces[0] = cur_pieces[0][1:]\n",
        "                cur_pieces.append(piece[-1])\n",
        "                new_pieces.extend(cur_pieces)\n",
        "            else:\n",
        "                new_pieces.append(piece)\n",
        "\n",
        "        return new_pieces\n",
        "\n",
        "    def _convert_token_to_id(self, token):\n",
        "        \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\n",
        "        return self.token2idx.get(token, self.token2idx[self.unk_token])\n",
        "\n",
        "    def _convert_id_to_token(self, index, return_unicode=True):\n",
        "        \"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"\n",
        "        return self.idx2token[index]\n",
        "\n",
        "    def convert_tokens_to_string(self, tokens):\n",
        "        \"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"\n",
        "        out_string = \"\".join(tokens).replace(SPIECE_UNDERLINE, \" \").strip()\n",
        "        return out_string\n",
        "\n",
        "    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
        "        \"\"\"\n",
        "        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n",
        "        by concatenating and adding special tokens.\n",
        "        A KoBERT sequence has the following format:\n",
        "            single sequence: [CLS] X [SEP]\n",
        "            pair of sequences: [CLS] A [SEP] B [SEP]\n",
        "        \"\"\"\n",
        "        if token_ids_1 is None:\n",
        "            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        sep = [self.sep_token_id]\n",
        "        return cls + token_ids_0 + sep + token_ids_1 + sep\n",
        "\n",
        "    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\n",
        "        \"\"\"\n",
        "        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n",
        "        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n",
        "        Args:\n",
        "            token_ids_0: list of ids (must not contain special tokens)\n",
        "            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n",
        "                for sequence pairs\n",
        "            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n",
        "                special tokens for the model\n",
        "        Returns:\n",
        "            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\n",
        "        \"\"\"\n",
        "\n",
        "        if already_has_special_tokens:\n",
        "            if token_ids_1 is not None:\n",
        "                raise ValueError(\n",
        "                    \"You should not supply a second sequence if the provided sequence of \"\n",
        "                    \"ids is already formated with special tokens for the model.\"\n",
        "                )\n",
        "            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\n",
        "\n",
        "        if token_ids_1 is not None:\n",
        "            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\n",
        "        return [1] + ([0] * len(token_ids_0)) + [1]\n",
        "\n",
        "    def create_token_type_ids_from_sequences(self, token_ids_0, token_ids_1=None):\n",
        "        \"\"\"\n",
        "        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n",
        "        A KoBERT sequence pair mask has the following format:\n",
        "        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
        "        | first sequence    | second sequence\n",
        "        if token_ids_1 is None, only returns the first portion of the mask (0's).\n",
        "        \"\"\"\n",
        "        sep = [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        if token_ids_1 is None:\n",
        "            return len(cls + token_ids_0 + sep) * [0]\n",
        "        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n",
        "\n",
        "    def save_vocabulary(self, save_directory):\n",
        "        \"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n",
        "            to a directory.\n",
        "        \"\"\"\n",
        "        if not os.path.isdir(save_directory):\n",
        "            logger.error(\"Vocabulary path ({}) should be a directory\".format(save_directory))\n",
        "            return\n",
        "\n",
        "        # 1. Save sentencepiece model\n",
        "        out_vocab_model = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_file\"])\n",
        "\n",
        "        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_model):\n",
        "            copyfile(self.vocab_file, out_vocab_model)\n",
        "\n",
        "        # 2. Save vocab.txt\n",
        "        index = 0\n",
        "        out_vocab_txt = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_txt\"])\n",
        "        with open(out_vocab_txt, \"w\", encoding=\"utf-8\") as writer:\n",
        "            for token, token_index in sorted(self.token2idx.items(), key=lambda kv: kv[1]):\n",
        "                if index != token_index:\n",
        "                    logger.warning(\n",
        "                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\n",
        "                        \" Please check that the vocabulary is not corrupted!\".format(out_vocab_txt)\n",
        "                    )\n",
        "                    index = token_index\n",
        "                writer.write(token + \"\\n\")\n",
        "                index += 1\n",
        "\n",
        "        return out_vocab_model, out_vocab_txt"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKiAuhmQT5Vk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_seed(seed = 2020):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(2020)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c76vPCtlTq53",
        "colab_type": "text"
      },
      "source": [
        "# ● train/test data set 소개\n",
        "* **NER 대회용 data set**과 **직접 스크래핑한 데이터**를 섞어 train/test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuSLLUCDP8bz",
        "colab_type": "text"
      },
      "source": [
        "## 1. NLP Challenge\n",
        "\n",
        "* 네이버와 창원대에서 개최한 NLP challenge의 train set\n",
        "* parsing이 잘못되는 부분이 있어 load후 약간의 전처리를 거친다.\n",
        "\n",
        "**아래와 같은 총 14개의 개체명 태그가 존재한다.**\n",
        "\n",
        "1. PERSON\tPER\t실존, 가상 등 인물명에 해당 하는 것\n",
        "2. FIELD\tFLD\t학문 분야 및 이론, 법칙, 기술 등\n",
        "3. ARTIFACTS_WORKS\tAFW\t인공물로 사람에 의해 창조된 대상물\n",
        "4. ORGANIZATION\tORG\t기관 및 단체와 회의/회담을 모두 포함\n",
        "5. LOCATION\tLOC\t지역명칭과 행정구역 명칭 등\n",
        "6. CIVILIZATION\tCVL\t문명 및 문화에 관련된 용어\n",
        "7. DATE\tDAT\t날짜\n",
        "8. TIME\tTIM\t시간\n",
        "9. NUMBER\tNUM\t숫자\n",
        "10. EVENT\tEVT\t특정 사건 및 사고 명칭과 행사 등\n",
        "11. ANIMAL\tANM\t동물\n",
        "12. PLANT\tPLT\t식물\n",
        "13. MATERIAL\tMAT\t금속, 암석, 화학물질 등\n",
        "14. TERM\tTRM\t의학 용어, IT곤련 용어 등 일반 용어를 총칭\n",
        "\n",
        "\n",
        "\n",
        "NOTE\n",
        "\n",
        "- index는 새로운 문장이 시작될 때마다 1로 초기화된다.\n",
        "- tag의 앞부분은 개체명의 의미를, 뒷부분은 BIO tagging을 뜻한다.\n",
        "- B는 개체명의 시작 어절, I는 끝 어절, -는 개체명이 아닌 어절을 뜻한다.\n",
        "- 두 개체명이 조합된 경우, 앞에 등장하는 개체명을 따라 태그를 부여한다. \n",
        "ex ) 포항공과대학교(LOC_B) 컴퓨터공학과(ORG_B) => LOC로 부여\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O2ta8VHT5Vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load #\n",
        "url = \"https://github.com/naver/nlp-challenge/raw/master/missions/ner/data/train/train_data\"\n",
        "urlretrieve(url, \"./train_data\")\n",
        "\n",
        "# preprocessing #\n",
        "train_raw = pd.read_csv(\"train_data\",sep=\"\\n\", header=None)\n",
        "train_raw = train_raw.applymap(lambda x:x.split(\"\\t\"))\n",
        "train = pd.DataFrame(train_raw[0].tolist(), columns = [\"index\",\"word\",\"tag\"])\n",
        "train['index'] = train['index'].map(int)\n",
        "train['word'] = train['word'].str.replace(\"．\", \".\", regex=False)\n",
        "train['word'] = train['word'].str.replace(r'[^ㄱ-ㅣ가-힣0-9a-zA-Z.]+', \"\", regex=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utTYKKT9L_Bh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "outputId": "8ca78294-5bdf-4374-9b5e-7e14f5f70701"
      },
      "source": [
        "train.head(20)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>비토리오</td>\n",
              "      <td>PER_B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>양일</td>\n",
              "      <td>DAT_B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>만에</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>영사관</td>\n",
              "      <td>ORG_B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>감호</td>\n",
              "      <td>CVL_B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>용퇴</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>항룡</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>압력설</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>의심만</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>가율</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>이</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2</td>\n",
              "      <td>음경동맥의</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3</td>\n",
              "      <td>직경이</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>NUM_B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5</td>\n",
              "      <td>19mm입니다</td>\n",
              "      <td>NUM_B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>6</td>\n",
              "      <td>.</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>9세이브로</td>\n",
              "      <td>NUM_B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2</td>\n",
              "      <td>구완</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3</td>\n",
              "      <td>30위인</td>\n",
              "      <td>NUM_B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>4</td>\n",
              "      <td>LG</td>\n",
              "      <td>ORG_B</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index     word    tag\n",
              "0       1     비토리오  PER_B\n",
              "1       2       양일  DAT_B\n",
              "2       3       만에      -\n",
              "3       4      영사관  ORG_B\n",
              "4       5       감호  CVL_B\n",
              "5       6       용퇴      -\n",
              "6       7       항룡      -\n",
              "7       8      압력설      -\n",
              "8       9      의심만      -\n",
              "9      10       가율      -\n",
              "10      1        이      -\n",
              "11      2    음경동맥의      -\n",
              "12      3      직경이      -\n",
              "13      4        8  NUM_B\n",
              "14      5  19mm입니다  NUM_B\n",
              "15      6        .      -\n",
              "16      1    9세이브로  NUM_B\n",
              "17      2       구완      -\n",
              "18      3     30위인  NUM_B\n",
              "19      4       LG  ORG_B"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd_MgF5-T5WA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = train.tag.unique()\n",
        "tag_to_label = {tag:i for i,tag in enumerate(labels)}\n",
        "tag_to_label[\"[PAD]\"] = len(labels)\n",
        "label_to_tag =  {label:tag for tag,label in tag_to_label.items()}\n",
        "\n",
        "data = train_raw[0].tolist()\n",
        "sentences, targets = [], []\n",
        "temp_sts, temp_targets = ['[CLS]'], [tag_to_label[\"-\"]]\n",
        "\n",
        "for sentence_index, word, tag in data:\n",
        "    # 새로운 문장이 등장했을 경우 SEP token을 추가하고 초기화시킨다.\n",
        "    if sentence_index == \"1\":\n",
        "        temp_sts.append(\"[SEP]\")\n",
        "        temp_targets.append(tag_to_label[\"-\"])\n",
        "\n",
        "        sentences.append(temp_sts)\n",
        "        targets.append(temp_targets)\n",
        "\n",
        "        temp_sts, temp_targets = ['[CLS]'], [tag_to_label[\"-\"]] # 초기화\n",
        "\n",
        "    temp_sts.append(word)\n",
        "    temp_targets.append(tag_to_label[tag])\n",
        "\n",
        "del [[sentences[0], targets[0]]] # 초깃값  ['[CLS]'], [tag_to_label[\"-\"]] 제거"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdtnYEjGPygs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "205bf199-2bd9-497d-db35-535a9829c786"
      },
      "source": [
        "sentences[0] # model input"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " '비토리오',\n",
              " '양일',\n",
              " '만에',\n",
              " '영사관',\n",
              " '감호',\n",
              " '용퇴,',\n",
              " '항룡',\n",
              " '압력설',\n",
              " '의심만',\n",
              " '가율',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqj4u8BZRyKU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "deb088e7-1673-4fc3-992f-dd585e126e02"
      },
      "source": [
        "targets[0] # model target"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 0, 1, 2, 3, 4, 2, 2, 2, 2, 2, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeetImziLJnn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "8c56b8626fe7438d8af186392d0ca0f3",
            "97b386a45bba47e58e57a06733102bf7",
            "20f91b582e5148babf5348b59ade59ee",
            "0901c3216eff426c8ab214dde6de2e06",
            "8c0511798dbc4c84b9108ee5780fbfea",
            "289c937e54054d92abbbd1c9b1c9aeb5",
            "baf6c5ccbb53471781dc84acc7279bcd",
            "708609714f744e118de7d853e0925909",
            "14fdbeef1b8a4a04aa28140b01a93255",
            "374e26941bb347589ed980e268fe746d",
            "ea4dccb4bb2c4687af071134da64c60a",
            "c7a8e850d3ad4a27abdafd5d1cac28b7",
            "afd048cf0b604886acc97044eb14f2f7",
            "64dd85adbeb142bd9be04a4a817bb033",
            "c97ec6d52db543dcb5856b91835c7197",
            "903ab9c69d6f434bae3396df6ab51156"
          ]
        },
        "outputId": "916d1106-6d61-4c62-c0d5-cd9be7135c71"
      },
      "source": [
        "tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c56b8626fe7438d8af186392d0ca0f3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=371391.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14fdbeef1b8a4a04aa28140b01a93255",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=77779.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SixXSZcNLDgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_and_preserve_labels(sentence, text_labels): # \n",
        "  tokenized_sentence = []\n",
        "  labels = []\n",
        "\n",
        "  for word, label in zip(sentence, text_labels):\n",
        "\n",
        "    tokenized_word = tokenizer.tokenize(word)\n",
        "    n_subwords = len(tokenized_word)\n",
        "\n",
        "    tokenized_sentence.extend(tokenized_word)\n",
        "    labels.extend([label] * n_subwords)\n",
        "\n",
        "  return tokenized_sentence, labels"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUaUpvmnT5WJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#####################\n",
        "# token화 된 data로 #\n",
        "#####################\n",
        "\n",
        "tokenized_texts_and_labels = [tokenize_and_preserve_labels(sent, labs)\n",
        "                              for sent, labs in zip(sentences, targets)]\n",
        "\n",
        "tokenized_texts = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels]\n",
        "labels = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels]\n",
        "\n",
        "# params #\n",
        "max_len = int(np.quantile(np.array([len(x) for x in tokenized_texts]), 0.975))\n",
        "batch_size = 32\n",
        "\n",
        "# input data #\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=max_len, dtype = \"int\",\n",
        "                          value=tokenizer.convert_tokens_to_ids(\"[PAD]\"),\n",
        "                          truncating=\"post\", padding=\"post\")\n",
        "tags = pad_sequences([lab for lab in labels], maxlen=max_len,\n",
        "                     value=tag_to_label[\"[PAD]\"], padding='post',\n",
        "                     dtype='int', truncating='post')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnW7S_HcTTza",
        "colab_type": "text"
      },
      "source": [
        "## 2. 한국민족문화대백과사전\n",
        "\n",
        "* 인물, 지명, 문화재, 유물, 단체 등의 카테고리를 이용하여 true tag를 생성\n",
        "\n",
        "  1. 각 카테고리에 접근한다.\n",
        "\n",
        "  2. 단체 카테고리에 속하는 단어들은 모두 `ORG `를 true tag로 지정한다.\n",
        "\n",
        "  3. NER 학습을 위해서는 문장이 필요하다. 해당 단어가 포함된 설명을 스크래핑한다.\n",
        "\n",
        "     > `교민` : `-` , `중국` : `-` , `관헌도` : `-` ,  `간민회` : `ORG_B`\n",
        "\n",
        "  4. true tag가 달리지 않은 `교민`, `중국`, `관헌도 `등은 **기존의 model(acc 97%)를 이용하여 약한 정답**을 생성한다.\n",
        "\n",
        "     > **기존 모델에 의한 정답**  `교민` : `PER` , `중국` : `LOC` , `관헌도` : `LOC`  ,`간민회` : `-`\n",
        "     >\n",
        "     > **스크래핑으로 생성한 정답**  `교민` : `-` , `중국` : `-` , `관헌도` : `-` ,  `간민회` : `ORG_B`\n",
        "     >\n",
        "     > **=> 최종 모델에 대한 정답 ** `교민` : `PER` , `중국` : `LOC` , `관헌도` : `LOC`  ,`간민회` : `ORG_B`\n",
        "\n",
        "\n",
        "\n",
        "#### NOTE\n",
        "\n",
        "* 전체 카테고리 중 \"유물\",\"유적\",\"작품\",\"제도\",\"지명\",\"문헌\",\"단체\",\"문화재\" 를 이용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRKvXLXJ8-3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "b5073007-870d-428b-c639-11d73c01918d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C5rswqW01N4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "targets_new = eval([line.rstrip('\\n') for line in open(\"/content/drive/My Drive/projects/targets_new.txt\")][0]) # targets_scraping.txt\n",
        "sentences_new = eval([line.rstrip('\\n') for line in open(\"/content/drive/My Drive/projects/sentences_new.txt\", encoding = 'utf-8')][0]) # sentences_scraping.tt"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIIF_MMF8oNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#####################\n",
        "# token화 된 data로 #\n",
        "#####################\n",
        "\n",
        "tokenized_texts_and_labels = [tokenize_and_preserve_labels(sent, labs)\n",
        "                              for sent, labs in zip(sentences_new, targets_new)]\n",
        "\n",
        "tokenized_texts = [['[CLS]'] + token_label_pair[0]  + ['[SEP]'] for token_label_pair in tokenized_texts_and_labels]\n",
        "labels = [[2] + token_label_pair[1] + [2] for token_label_pair in tokenized_texts_and_labels]\n",
        "\n",
        "input_ids_new = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=max_len, dtype = \"int\",\n",
        "                          value=tokenizer.convert_tokens_to_ids(\"[PAD]\"),\n",
        "                          truncating=\"post\", padding=\"post\")\n",
        "tags_new = pad_sequences([lab for lab in labels], maxlen=max_len,\n",
        "                     value=tag_to_label[\"[PAD]\"], padding='post',\n",
        "                     dtype='int', truncating='post')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBMvKeXNZlTw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7d443dd9-15e3-4200-fdcf-aad404da64aa"
      },
      "source": [
        "len(input_ids_new) + len(input_ids)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95194"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUnqP2RfaaE3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ffc95546-8ba4-4b96-9ce9-af1f24cfe5fa"
      },
      "source": [
        " len(input_ids)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "89999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9HYvnuAaoEf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b67a1022-78f0-4a90-c0ab-c08adb553031"
      },
      "source": [
        "len(input_ids_new) + 1063571"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1068766"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhKpXUMNT5XV",
        "colab_type": "text"
      },
      "source": [
        "# ● class DistilKoBertCRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BX-LhsOT5Xb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "13b1be2c-7b7c-4ddc-d2f2-40041dee70aa"
      },
      "source": [
        "class DistilKobertCRF(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(DistilKobertCRF, self).__init__()\n",
        "\n",
        "        self.hidden_size = 768\n",
        "        self.num_classes = num_classes\n",
        "        self.pad_id = 1\n",
        "\n",
        "        self.bert = DistilBertModel.from_pretrained(\"monologg/distilkobert\")\n",
        "        self.FC = torch.nn.Linear(self.hidden_size,self.num_classes)\n",
        "        self.crf = CRF(num_tags = num_classes, batch_first = True)\n",
        "\n",
        "    def forward(self, input_ids, real_tags = None):\n",
        "        attention_mask = input_ids.ne(self.pad_id).float()\n",
        "        last_hidden_state = self.bert.forward(input_ids, attention_mask)\n",
        "        dense = self.FC(last_hidden_state[0])\n",
        "        \n",
        "        if real_tags is not None:\n",
        "            log_likelihood = self.crf(dense,real_tags)\n",
        "            pred_tags = self.crf.decode(dense)\n",
        "            return log_likelihood, pred_tags\n",
        "        \n",
        "        else:\n",
        "            pred_tags =  self.crf.decode(dense)\n",
        "            return pred_tags\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IktQRYiRIDz",
        "colab_type": "text"
      },
      "source": [
        "# ● Train\n",
        "* NLP challenge data와 한국민족문화대백과사전 데이터를 각각 80%씩 추출하여 합친 후 train data로 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0wVdg3PR1Jp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.save(model.state_dict(),\"/content/drive/My Drive/projects/ner_model_weight\")\n",
        "# torch.save(model, \"/content/drive/My Drive/projects/ner_model_structure\")\n",
        "\n",
        "# model = DistilKobertCRF(num_classes = 30)\n",
        "# model.load_state_dict(torch.load(\"/content/drive/My Drive/projects/ner_model_weight_concat_epoch_18\"))\n",
        "# model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA2pTC8NDssN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_concat_train = np.concatenate((input_ids[:train_size],input_ids_new[:train_size_2]),axis=0)\n",
        "tags_concat_train = np.concatenate((tags[:train_size],tags_new[:train_size_2]),axis=0)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RULmNflGNOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_concat_test = np.concatenate((input_ids[train_size:],input_ids_new[train_size_2:]),axis=0)\n",
        "tags_concat_test = np.concatenate((tags[train_size:],tags_new[train_size_2:]),axis=0)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GF9e9Se4_1O_",
        "colab": {}
      },
      "source": [
        "train_ids_loader = torch.utils.data.DataLoader(inputs_concat_train, batch_size=batch_size,drop_last=True,shuffle=False)\n",
        "train_tags_loader = torch.utils.data.DataLoader(tags_concat_train, batch_size=batch_size,drop_last=True, shuffle=False)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTkyY1-LRDjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_ids_loader = torch.utils.data.DataLoader(inputs_concat_test, batch_size=batch_size,drop_last=True,shuffle=False)\n",
        "test_tags_loader = torch.utils.data.DataLoader(tags_concat_test, batch_size=batch_size,drop_last=True, shuffle=False)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJXX_JPjRygH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "train_size = int(len(input_ids)*0.8)\n",
        "train_size_2 = int(len(targets_new)*0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvlgGBlyT5Xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = DistilKobertCRF(num_classes = 30)\n",
        "model.to(device)\n",
        "model.train()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00002)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWayxUpOSAr0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8480aaac-25f5-4a0d-873d-0f0907f97ee8"
      },
      "source": [
        "model"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilKobertCRF(\n",
              "  (bert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (FC): Linear(in_features=768, out_features=30, bias=True)\n",
              "  (crf): CRF(num_tags=30)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTpJY7sAJzUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 18"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpQ7orj1ecj-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22285ece-760d-489c-bb1f-e9dc5e12b86f"
      },
      "source": [
        "train_accuracy = []\n",
        "loss_ = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(\"Epoch:\",epoch ,\"================================================================\")\n",
        "    for iters, [input_id, true_tag] in enumerate(zip(train_ids_loader, train_tags_loader)):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_id = input_id.long().to(device)\n",
        "        true_tag = true_tag.long().to(device)\n",
        "        \n",
        "        log_likelihood , pred_tag = model.forward(input_id, true_tag)\n",
        "        loss = -1*log_likelihood\n",
        "        loss = loss.mean()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if iters % 100 == 0:\n",
        "            true_tag,pred_tag = true_tag.cpu(),torch.tensor(pred_tag).cpu()\n",
        "\n",
        "            correct_iters = (pred_tag == true_tag).float()[true_tag != tag_to_label['[PAD]']].sum()\n",
        "            total_iters = len(true_tag[true_tag != tag_to_label['[PAD]'] ])\n",
        "\n",
        "            temp_acc = correct_iters/total_iters\n",
        "            train_accuracy.append(temp_acc.cpu().detach().numpy())\n",
        "\n",
        "            print(f\"accuracy({iters}) :\",temp_acc)\n",
        "\n",
        "    print(\"Loss :\", loss)\n",
        "    loss_.append(loss.cpu().detach().numpy())  "
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 ================================================================\n",
            "accuracy(0) : tensor(0.0366)\n",
            "accuracy(100) : tensor(0.6354)\n",
            "accuracy(200) : tensor(0.5923)\n",
            "accuracy(300) : tensor(0.6087)\n",
            "accuracy(400) : tensor(0.7132)\n",
            "accuracy(500) : tensor(0.6984)\n",
            "accuracy(600) : tensor(0.6844)\n",
            "accuracy(700) : tensor(0.8034)\n",
            "accuracy(800) : tensor(0.7384)\n",
            "accuracy(900) : tensor(0.7978)\n",
            "accuracy(1000) : tensor(0.7968)\n",
            "accuracy(1100) : tensor(0.7571)\n",
            "accuracy(1200) : tensor(0.8026)\n",
            "accuracy(1300) : tensor(0.8030)\n",
            "accuracy(1400) : tensor(0.8018)\n",
            "accuracy(1500) : tensor(0.8424)\n",
            "accuracy(1600) : tensor(0.7835)\n",
            "accuracy(1700) : tensor(0.8377)\n",
            "accuracy(1800) : tensor(0.8170)\n",
            "accuracy(1900) : tensor(0.8616)\n",
            "accuracy(2000) : tensor(0.8195)\n",
            "accuracy(2100) : tensor(0.8553)\n",
            "accuracy(2200) : tensor(0.8067)\n",
            "accuracy(2300) : tensor(0.8450)\n",
            "Loss : tensor(909.0316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch: 1 ================================================================\n",
            "accuracy(0) : tensor(0.7925)\n",
            "accuracy(100) : tensor(0.8579)\n",
            "accuracy(200) : tensor(0.8373)\n",
            "accuracy(300) : tensor(0.8005)\n",
            "accuracy(400) : tensor(0.8626)\n",
            "accuracy(500) : tensor(0.8452)\n",
            "accuracy(600) : tensor(0.8110)\n",
            "accuracy(700) : tensor(0.8800)\n",
            "accuracy(800) : tensor(0.8250)\n",
            "accuracy(900) : tensor(0.8560)\n",
            "accuracy(1000) : tensor(0.8636)\n",
            "accuracy(1100) : tensor(0.8395)\n",
            "accuracy(1200) : tensor(0.8750)\n",
            "accuracy(1300) : tensor(0.8520)\n",
            "accuracy(1400) : tensor(0.8429)\n",
            "accuracy(1500) : tensor(0.8821)\n",
            "accuracy(1600) : tensor(0.8784)\n",
            "accuracy(1700) : tensor(0.8817)\n",
            "accuracy(1800) : tensor(0.8725)\n",
            "accuracy(1900) : tensor(0.9048)\n",
            "accuracy(2000) : tensor(0.8668)\n",
            "accuracy(2100) : tensor(0.9005)\n",
            "accuracy(2200) : tensor(0.8414)\n",
            "accuracy(2300) : tensor(0.8709)\n",
            "Loss : tensor(620.7760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch: 2 ================================================================\n",
            "accuracy(0) : tensor(0.8789)\n",
            "accuracy(100) : tensor(0.8856)\n",
            "accuracy(200) : tensor(0.8852)\n",
            "accuracy(300) : tensor(0.8465)\n",
            "accuracy(400) : tensor(0.8582)\n",
            "accuracy(500) : tensor(0.8837)\n",
            "accuracy(600) : tensor(0.8268)\n",
            "accuracy(700) : tensor(0.8881)\n",
            "accuracy(800) : tensor(0.8527)\n",
            "accuracy(900) : tensor(0.8733)\n",
            "accuracy(1000) : tensor(0.8956)\n",
            "accuracy(1100) : tensor(0.8688)\n",
            "accuracy(1200) : tensor(0.8853)\n",
            "accuracy(1300) : tensor(0.8669)\n",
            "accuracy(1400) : tensor(0.8573)\n",
            "accuracy(1500) : tensor(0.9036)\n",
            "accuracy(1600) : tensor(0.8889)\n",
            "accuracy(1700) : tensor(0.9037)\n",
            "accuracy(1800) : tensor(0.8930)\n",
            "accuracy(1900) : tensor(0.9081)\n",
            "accuracy(2000) : tensor(0.8703)\n",
            "accuracy(2100) : tensor(0.9014)\n",
            "accuracy(2200) : tensor(0.8596)\n",
            "accuracy(2300) : tensor(0.8964)\n",
            "Loss : tensor(552.3890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch: 3 ================================================================\n",
            "accuracy(0) : tensor(0.8939)\n",
            "accuracy(100) : tensor(0.8740)\n",
            "accuracy(200) : tensor(0.8909)\n",
            "accuracy(300) : tensor(0.8559)\n",
            "accuracy(400) : tensor(0.8790)\n",
            "accuracy(500) : tensor(0.8845)\n",
            "accuracy(600) : tensor(0.8454)\n",
            "accuracy(700) : tensor(0.9062)\n",
            "accuracy(800) : tensor(0.8679)\n",
            "accuracy(900) : tensor(0.8815)\n",
            "accuracy(1000) : tensor(0.9257)\n",
            "accuracy(1100) : tensor(0.8635)\n",
            "accuracy(1200) : tensor(0.8862)\n",
            "accuracy(1300) : tensor(0.8783)\n",
            "accuracy(1400) : tensor(0.8758)\n",
            "accuracy(1500) : tensor(0.9002)\n",
            "accuracy(1600) : tensor(0.9138)\n",
            "accuracy(1700) : tensor(0.9120)\n",
            "accuracy(1800) : tensor(0.9028)\n",
            "accuracy(1900) : tensor(0.9468)\n",
            "accuracy(2000) : tensor(0.9010)\n",
            "accuracy(2100) : tensor(0.9051)\n",
            "accuracy(2200) : tensor(0.8469)\n",
            "accuracy(2300) : tensor(0.8868)\n",
            "Loss : tensor(453.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch: 4 ================================================================\n",
            "accuracy(0) : tensor(0.9089)\n",
            "accuracy(100) : tensor(0.8963)\n",
            "accuracy(200) : tensor(0.8852)\n",
            "accuracy(300) : tensor(0.8730)\n",
            "accuracy(400) : tensor(0.8899)\n",
            "accuracy(500) : tensor(0.9120)\n",
            "accuracy(600) : tensor(0.8641)\n",
            "accuracy(700) : tensor(0.8972)\n",
            "accuracy(800) : tensor(0.8813)\n",
            "accuracy(900) : tensor(0.8733)\n",
            "accuracy(1000) : tensor(0.9200)\n",
            "accuracy(1100) : tensor(0.8732)\n",
            "accuracy(1200) : tensor(0.8966)\n",
            "accuracy(1300) : tensor(0.8792)\n",
            "accuracy(1400) : tensor(0.9097)\n",
            "accuracy(1500) : tensor(0.9116)\n",
            "accuracy(1600) : tensor(0.9176)\n",
            "accuracy(1700) : tensor(0.9152)\n",
            "accuracy(1800) : tensor(0.9208)\n",
            "accuracy(1900) : tensor(0.9269)\n",
            "accuracy(2000) : tensor(0.9334)\n",
            "accuracy(2100) : tensor(0.9132)\n",
            "accuracy(2200) : tensor(0.8678)\n",
            "accuracy(2300) : tensor(0.8843)\n",
            "Loss : tensor(469.5844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch: 5 ================================================================\n",
            "accuracy(0) : tensor(0.9108)\n",
            "accuracy(100) : tensor(0.9214)\n",
            "accuracy(200) : tensor(0.8928)\n",
            "accuracy(300) : tensor(0.8696)\n",
            "accuracy(400) : tensor(0.8899)\n",
            "accuracy(500) : tensor(0.9238)\n",
            "accuracy(600) : tensor(0.8631)\n",
            "accuracy(700) : tensor(0.9133)\n",
            "accuracy(800) : tensor(0.8946)\n",
            "accuracy(900) : tensor(0.9009)\n",
            "accuracy(1000) : tensor(0.9370)\n",
            "accuracy(1100) : tensor(0.8972)\n",
            "accuracy(1200) : tensor(0.9069)\n",
            "accuracy(1300) : tensor(0.8862)\n",
            "accuracy(1400) : tensor(0.9076)\n",
            "accuracy(1500) : tensor(0.9093)\n",
            "accuracy(1600) : tensor(0.9148)\n",
            "accuracy(1700) : tensor(0.9267)\n",
            "accuracy(1800) : tensor(0.9101)\n",
            "accuracy(1900) : tensor(0.9468)\n",
            "accuracy(2000) : tensor(0.9281)\n",
            "accuracy(2100) : tensor(0.8960)\n",
            "accuracy(2200) : tensor(0.8851)\n",
            "accuracy(2300) : tensor(0.8972)\n",
            "Loss : tensor(408.7030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch: 6 ================================================================\n",
            "accuracy(0) : tensor(0.8901)\n",
            "accuracy(100) : tensor(0.9080)\n",
            "accuracy(200) : tensor(0.9062)\n",
            "accuracy(300) : tensor(0.8772)\n",
            "accuracy(400) : tensor(0.8702)\n",
            "accuracy(500) : tensor(0.9285)\n",
            "accuracy(600) : tensor(0.8864)\n",
            "accuracy(700) : tensor(0.9183)\n",
            "accuracy(800) : tensor(0.8964)\n",
            "accuracy(900) : tensor(0.9050)\n",
            "accuracy(1000) : tensor(0.9257)\n",
            "accuracy(1100) : tensor(0.8918)\n",
            "accuracy(1200) : tensor(0.9129)\n",
            "accuracy(1300) : tensor(0.8818)\n",
            "accuracy(1400) : tensor(0.9199)\n",
            "accuracy(1500) : tensor(0.9059)\n",
            "accuracy(1600) : tensor(0.9157)\n",
            "accuracy(1700) : tensor(0.9173)\n",
            "accuracy(1800) : tensor(0.9142)\n",
            "accuracy(1900) : tensor(0.9291)\n",
            "accuracy(2000) : tensor(0.9229)\n",
            "accuracy(2100) : tensor(0.9069)\n",
            "accuracy(2200) : tensor(0.8906)\n",
            "accuracy(2300) : tensor(0.9094)\n",
            "Loss : tensor(353.3069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch: 7 ================================================================\n",
            "accuracy(0) : tensor(0.9324)\n",
            "accuracy(100) : tensor(0.9053)\n",
            "accuracy(200) : tensor(0.9014)\n",
            "accuracy(300) : tensor(0.8798)\n",
            "accuracy(400) : tensor(0.8909)\n",
            "accuracy(500) : tensor(0.9379)\n",
            "accuracy(600) : tensor(0.8734)\n",
            "accuracy(700) : tensor(0.9325)\n",
            "accuracy(800) : tensor(0.8920)\n",
            "accuracy(900) : tensor(0.9173)\n",
            "accuracy(1000) : tensor(0.9360)\n",
            "accuracy(1100) : tensor(0.8980)\n",
            "accuracy(1200) : tensor(0.9353)\n",
            "accuracy(1300) : tensor(0.9011)\n",
            "accuracy(1400) : tensor(0.9158)\n",
            "accuracy(1500) : tensor(0.9172)\n",
            "accuracy(1600) : tensor(0.9157)\n",
            "accuracy(1700) : tensor(0.9330)\n",
            "accuracy(1800) : tensor(0.9387)\n",
            "accuracy(1900) : tensor(0.9502)\n",
            "accuracy(2000) : tensor(0.9308)\n",
            "accuracy(2100) : tensor(0.9114)\n",
            "accuracy(2200) : tensor(0.9088)\n",
            "accuracy(2300) : tensor(0.9127)\n",
            "Loss : tensor(345.0096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch: 8 ================================================================\n",
            "accuracy(0) : tensor(0.9239)\n",
            "accuracy(100) : tensor(0.9348)\n",
            "accuracy(200) : tensor(0.9053)\n",
            "accuracy(300) : tensor(0.8841)\n",
            "accuracy(400) : tensor(0.9204)\n",
            "accuracy(500) : tensor(0.9379)\n",
            "accuracy(600) : tensor(0.8892)\n",
            "accuracy(700) : tensor(0.9315)\n",
            "accuracy(800) : tensor(0.8920)\n",
            "accuracy(900) : tensor(0.9152)\n",
            "accuracy(1000) : tensor(0.9464)\n",
            "accuracy(1100) : tensor(0.9025)\n",
            "accuracy(1200) : tensor(0.9491)\n",
            "accuracy(1300) : tensor(0.9054)\n",
            "accuracy(1400) : tensor(0.9374)\n",
            "accuracy(1500) : tensor(0.9286)\n",
            "accuracy(1600) : tensor(0.9282)\n",
            "accuracy(1700) : tensor(0.9319)\n",
            "accuracy(1800) : tensor(0.9338)\n",
            "accuracy(1900) : tensor(0.9480)\n",
            "accuracy(2000) : tensor(0.9430)\n",
            "accuracy(2100) : tensor(0.9177)\n",
            "accuracy(2200) : tensor(0.9079)\n",
            "accuracy(2300) : tensor(0.9119)\n",
            "Loss : tensor(329.5102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch: 9 ================================================================\n",
            "accuracy(0) : tensor(0.9174)\n",
            "accuracy(100) : tensor(0.9115)\n",
            "accuracy(200) : tensor(0.9301)\n",
            "accuracy(300) : tensor(0.8687)\n",
            "accuracy(400) : tensor(0.9062)\n",
            "accuracy(500) : tensor(0.9340)\n",
            "accuracy(600) : tensor(0.9227)\n",
            "accuracy(700) : tensor(0.9385)\n",
            "accuracy(800) : tensor(0.9027)\n",
            "accuracy(900) : tensor(0.9101)\n",
            "accuracy(1000) : tensor(0.9379)\n",
            "accuracy(1100) : tensor(0.9158)\n",
            "accuracy(1200) : tensor(0.9293)\n",
            "accuracy(1300) : tensor(0.8993)\n",
            "accuracy(1400) : tensor(0.9292)\n",
            "accuracy(1500) : tensor(0.9286)\n",
            "accuracy(1600) : tensor(0.9148)\n",
            "accuracy(1700) : tensor(0.9435)\n",
            "accuracy(1800) : tensor(0.9485)\n",
            "accuracy(1900) : tensor(0.9468)\n",
            "accuracy(2000) : tensor(0.9281)\n",
            "accuracy(2100) : tensor(0.9177)\n",
            "accuracy(2200) : tensor(0.8961)\n",
            "accuracy(2300) : tensor(0.9286)\n",
            "Loss : tensor(314.7027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch: 10 ================================================================\n",
            "accuracy(0) : tensor(0.9239)\n",
            "accuracy(100) : tensor(0.9348)\n",
            "accuracy(200) : tensor(0.9273)\n",
            "accuracy(300) : tensor(0.9011)\n",
            "accuracy(400) : tensor(0.9128)\n",
            "accuracy(500) : tensor(0.9285)\n",
            "accuracy(600) : tensor(0.9078)\n",
            "accuracy(700) : tensor(0.9435)\n",
            "accuracy(800) : tensor(0.9116)\n",
            "accuracy(900) : tensor(0.9224)\n",
            "accuracy(1000) : tensor(0.9379)\n",
            "accuracy(1100) : tensor(0.9353)\n",
            "accuracy(1200) : tensor(0.9414)\n",
            "accuracy(1300) : tensor(0.9081)\n",
            "accuracy(1400) : tensor(0.9394)\n",
            "accuracy(1500) : tensor(0.9308)\n",
            "accuracy(1600) : tensor(0.9310)\n",
            "accuracy(1700) : tensor(0.9487)\n",
            "accuracy(1800) : tensor(0.9371)\n",
            "accuracy(1900) : tensor(0.9612)\n",
            "accuracy(2000) : tensor(0.9360)\n",
            "accuracy(2100) : tensor(0.9439)\n",
            "accuracy(2200) : tensor(0.9134)\n",
            "accuracy(2300) : tensor(0.9148)\n",
            "Loss : tensor(272.4322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch: 11 ================================================================\n",
            "accuracy(0) : tensor(0.9352)\n",
            "accuracy(100) : tensor(0.9491)\n",
            "accuracy(200) : tensor(0.9225)\n",
            "accuracy(300) : tensor(0.9045)\n",
            "accuracy(400) : tensor(0.9171)\n",
            "accuracy(500) : tensor(0.9466)\n",
            "accuracy(600) : tensor(0.8948)\n",
            "accuracy(700) : tensor(0.9425)\n",
            "accuracy(800) : tensor(0.9045)\n",
            "accuracy(900) : tensor(0.9142)\n",
            "accuracy(1000) : tensor(0.9407)\n",
            "accuracy(1100) : tensor(0.9238)\n",
            "accuracy(1200) : tensor(0.9414)\n",
            "accuracy(1300) : tensor(0.9247)\n",
            "accuracy(1400) : tensor(0.9353)\n",
            "accuracy(1500) : tensor(0.9399)\n",
            "accuracy(1600) : tensor(0.9397)\n",
            "accuracy(1700) : tensor(0.9508)\n",
            "accuracy(1800) : tensor(0.9493)\n",
            "accuracy(1900) : tensor(0.9380)\n",
            "accuracy(2000) : tensor(0.9316)\n",
            "accuracy(2100) : tensor(0.9476)\n",
            "accuracy(2200) : tensor(0.9198)\n",
            "accuracy(2300) : tensor(0.9144)\n",
            "Loss : tensor(262.9152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch: 12 ================================================================\n",
            "accuracy(0) : tensor(0.9587)\n",
            "accuracy(100) : tensor(0.9419)\n",
            "accuracy(200) : tensor(0.9311)\n",
            "accuracy(300) : tensor(0.9071)\n",
            "accuracy(400) : tensor(0.9117)\n",
            "accuracy(500) : tensor(0.9560)\n",
            "accuracy(600) : tensor(0.9199)\n",
            "accuracy(700) : tensor(0.9435)\n",
            "accuracy(800) : tensor(0.9357)\n",
            "accuracy(900) : tensor(0.9091)\n",
            "accuracy(1000) : tensor(0.9501)\n",
            "accuracy(1100) : tensor(0.9335)\n",
            "accuracy(1200) : tensor(0.9509)\n",
            "accuracy(1300) : tensor(0.9483)\n",
            "accuracy(1400) : tensor(0.9456)\n",
            "accuracy(1500) : tensor(0.9456)\n",
            "accuracy(1600) : tensor(0.9416)\n",
            "accuracy(1700) : tensor(0.9445)\n",
            "accuracy(1800) : tensor(0.9641)\n",
            "accuracy(1900) : tensor(0.9535)\n",
            "accuracy(2000) : tensor(0.9509)\n",
            "accuracy(2100) : tensor(0.9448)\n",
            "accuracy(2200) : tensor(0.9107)\n",
            "accuracy(2300) : tensor(0.9202)\n",
            "Loss : tensor(219.7908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch: 13 ================================================================\n",
            "accuracy(0) : tensor(0.9549)\n",
            "accuracy(100) : tensor(0.9464)\n",
            "accuracy(200) : tensor(0.9330)\n",
            "accuracy(300) : tensor(0.9130)\n",
            "accuracy(400) : tensor(0.9324)\n",
            "accuracy(500) : tensor(0.9403)\n",
            "accuracy(600) : tensor(0.9255)\n",
            "accuracy(700) : tensor(0.9315)\n",
            "accuracy(800) : tensor(0.9241)\n",
            "accuracy(900) : tensor(0.9346)\n",
            "accuracy(1000) : tensor(0.9511)\n",
            "accuracy(1100) : tensor(0.9291)\n",
            "accuracy(1200) : tensor(0.9509)\n",
            "accuracy(1300) : tensor(0.9264)\n",
            "accuracy(1400) : tensor(0.9435)\n",
            "accuracy(1500) : tensor(0.9512)\n",
            "accuracy(1600) : tensor(0.9406)\n",
            "accuracy(1700) : tensor(0.9393)\n",
            "accuracy(1800) : tensor(0.9608)\n",
            "accuracy(1900) : tensor(0.9734)\n",
            "accuracy(2000) : tensor(0.9465)\n",
            "accuracy(2100) : tensor(0.9494)\n",
            "accuracy(2200) : tensor(0.9289)\n",
            "accuracy(2300) : tensor(0.9311)\n",
            "Loss : tensor(201.5531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch: 14 ================================================================\n",
            "accuracy(0) : tensor(0.9418)\n",
            "accuracy(100) : tensor(0.9500)\n",
            "accuracy(200) : tensor(0.9311)\n",
            "accuracy(300) : tensor(0.9139)\n",
            "accuracy(400) : tensor(0.9335)\n",
            "accuracy(500) : tensor(0.9482)\n",
            "accuracy(600) : tensor(0.9320)\n",
            "accuracy(700) : tensor(0.9496)\n",
            "accuracy(800) : tensor(0.9295)\n",
            "accuracy(900) : tensor(0.9132)\n",
            "accuracy(1000) : tensor(0.9690)\n",
            "accuracy(1100) : tensor(0.9397)\n",
            "accuracy(1200) : tensor(0.9509)\n",
            "accuracy(1300) : tensor(0.9124)\n",
            "accuracy(1400) : tensor(0.9466)\n",
            "accuracy(1500) : tensor(0.9512)\n",
            "accuracy(1600) : tensor(0.9473)\n",
            "accuracy(1700) : tensor(0.9581)\n",
            "accuracy(1800) : tensor(0.9616)\n",
            "accuracy(1900) : tensor(0.9734)\n",
            "accuracy(2000) : tensor(0.9509)\n",
            "accuracy(2100) : tensor(0.9394)\n",
            "accuracy(2200) : tensor(0.9462)\n",
            "accuracy(2300) : tensor(0.9294)\n",
            "Loss : tensor(253.2706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch: 15 ================================================================\n",
            "accuracy(0) : tensor(0.9559)\n",
            "accuracy(100) : tensor(0.9508)\n",
            "accuracy(200) : tensor(0.9321)\n",
            "accuracy(300) : tensor(0.9173)\n",
            "accuracy(400) : tensor(0.9389)\n",
            "accuracy(500) : tensor(0.9576)\n",
            "accuracy(600) : tensor(0.9339)\n",
            "accuracy(700) : tensor(0.9556)\n",
            "accuracy(800) : tensor(0.9348)\n",
            "accuracy(900) : tensor(0.9326)\n",
            "accuracy(1000) : tensor(0.9501)\n",
            "accuracy(1100) : tensor(0.9583)\n",
            "accuracy(1200) : tensor(0.9491)\n",
            "accuracy(1300) : tensor(0.9238)\n",
            "accuracy(1400) : tensor(0.9363)\n",
            "accuracy(1500) : tensor(0.9444)\n",
            "accuracy(1600) : tensor(0.9550)\n",
            "accuracy(1700) : tensor(0.9539)\n",
            "accuracy(1800) : tensor(0.9641)\n",
            "accuracy(1900) : tensor(0.9635)\n",
            "accuracy(2000) : tensor(0.9579)\n",
            "accuracy(2100) : tensor(0.9575)\n",
            "accuracy(2200) : tensor(0.9234)\n",
            "accuracy(2300) : tensor(0.9323)\n",
            "Loss : tensor(237.9541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch: 16 ================================================================\n",
            "accuracy(0) : tensor(0.9559)\n",
            "accuracy(100) : tensor(0.9374)\n",
            "accuracy(200) : tensor(0.9435)\n",
            "accuracy(300) : tensor(0.9250)\n",
            "accuracy(400) : tensor(0.9444)\n",
            "accuracy(500) : tensor(0.9513)\n",
            "accuracy(600) : tensor(0.9367)\n",
            "accuracy(700) : tensor(0.9385)\n",
            "accuracy(800) : tensor(0.9393)\n",
            "accuracy(900) : tensor(0.9336)\n",
            "accuracy(1000) : tensor(0.9680)\n",
            "accuracy(1100) : tensor(0.9441)\n",
            "accuracy(1200) : tensor(0.9595)\n",
            "accuracy(1300) : tensor(0.9466)\n",
            "accuracy(1400) : tensor(0.9497)\n",
            "accuracy(1500) : tensor(0.9478)\n",
            "accuracy(1600) : tensor(0.9454)\n",
            "accuracy(1700) : tensor(0.9539)\n",
            "accuracy(1800) : tensor(0.9461)\n",
            "accuracy(1900) : tensor(0.9601)\n",
            "accuracy(2000) : tensor(0.9658)\n",
            "accuracy(2100) : tensor(0.9620)\n",
            "accuracy(2200) : tensor(0.9389)\n",
            "accuracy(2300) : tensor(0.9428)\n",
            "Loss : tensor(198.4218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "Epoch: 17 ================================================================\n",
            "accuracy(0) : tensor(0.9540)\n",
            "accuracy(100) : tensor(0.9544)\n",
            "accuracy(200) : tensor(0.9455)\n",
            "accuracy(300) : tensor(0.9292)\n",
            "accuracy(400) : tensor(0.9346)\n",
            "accuracy(500) : tensor(0.9442)\n",
            "accuracy(600) : tensor(0.9274)\n",
            "accuracy(700) : tensor(0.9425)\n",
            "accuracy(800) : tensor(0.9500)\n",
            "accuracy(900) : tensor(0.9408)\n",
            "accuracy(1000) : tensor(0.9680)\n",
            "accuracy(1100) : tensor(0.9433)\n",
            "accuracy(1200) : tensor(0.9534)\n",
            "accuracy(1300) : tensor(0.9335)\n",
            "accuracy(1400) : tensor(0.9784)\n",
            "accuracy(1500) : tensor(0.9410)\n",
            "accuracy(1600) : tensor(0.9607)\n",
            "accuracy(1700) : tensor(0.9539)\n",
            "accuracy(1800) : tensor(0.9681)\n",
            "accuracy(1900) : tensor(0.9590)\n",
            "accuracy(2000) : tensor(0.9597)\n",
            "accuracy(2100) : tensor(0.9647)\n",
            "accuracy(2200) : tensor(0.9426)\n",
            "accuracy(2300) : tensor(0.9344)\n",
            "Loss : tensor(227.8294, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaG6c2eyU2uJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.save(model.state_dict(),\"/content/drive/My Drive/projects/ner_model_weight_concat_epoch_28\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9uJqazkT5YV",
        "colab_type": "text"
      },
      "source": [
        "## evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg8ne3FQouMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = DistilKobertCRF(num_classes = 30)\n",
        "# model.load_state_dict(torch.load(\"/content/drive/My Drive/projects/ner_model_weight_concat_epoch_18\"))\n",
        "# model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZuGR_EapGBM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "2b229146-e3e5-4466-cb17-f8268c1ca19b"
      },
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for iters, [input_id, true_tag] in enumerate(zip(test_ids_loader, test_tags_loader)):\n",
        "        \n",
        "        input_id = input_id.long().to(device)\n",
        "        true_tag = true_tag.long()\n",
        "        \n",
        "        pred_tag = model.forward(input_id)\n",
        "        pred_tag = torch.tensor(pred_tag)\n",
        "        \n",
        "        correct_iters = (pred_tag == true_tag).float()[true_tag != tag_to_label['[PAD]']].sum()\n",
        "        total_iters = len(true_tag[true_tag != tag_to_label['[PAD]'] ])\n",
        "        \n",
        "        correct += correct_iters\n",
        "        total += total_iters\n",
        "        \n",
        "        if not iters % 50:\n",
        "            print(f\"{iters} - accuracy : {correct_iters/total_iters}\")\n",
        "\n",
        "    print(\"Accuracy of the model: {}\".format(correct/total))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 - accuracy : 0.9451277256011963\n",
            "50 - accuracy : 0.9257143139839172\n",
            "100 - accuracy : 0.917475700378418\n",
            "150 - accuracy : 0.9093511700630188\n",
            "200 - accuracy : 0.9065108299255371\n",
            "250 - accuracy : 0.8427543640136719\n",
            "300 - accuracy : 0.9092559218406677\n",
            "350 - accuracy : 0.9175340533256531\n",
            "400 - accuracy : 0.9255319237709045\n",
            "450 - accuracy : 0.8990195989608765\n",
            "500 - accuracy : 0.90444016456604\n",
            "550 - accuracy : 0.885660707950592\n",
            "Accuracy of the model: 0.9060052633285522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SKilEeseoqbi"
      },
      "source": [
        "## f1, confusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cDOPnjy9oqbl",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjwDajw8T5gu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(classification_report(val_tags_l, y_predicted_l, labels=f_label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "okpubSYpoqb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "f833f5f5-cca0-41a0-ddfa-cfa201b41218"
      },
      "source": [
        "f1_score(val_tags_l, y_predicted_l,average=None,labels=f_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.88120297, 0.92668941, 0.95711281, 0.84819191, 0.82424621,\n",
              "       0.94676573, 0.77282801, 0.8027807 , 0.81881559, 0.57605496,\n",
              "       0.66418492, 0.81123181, 0.4847865 , 0.77518523, 0.87061184,\n",
              "       0.89298044, 0.7002728 , 0.90532349, 0.47955903, 0.73890533,\n",
              "       0.48627451, 0.        , 0.56848433, 0.17040359, 0.1957905 ,\n",
              "       0.15189873, 0.        , 0.        , 0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAa57BSFrUL4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "5ce41592-0ef1-4bb9-d63d-d6ea7a2e1bd9"
      },
      "source": [
        "f1_score(val_tags_l, y_predicted_l,average=None,labels=f_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.88120297, 0.92668941, 0.95711281, 0.84819191, 0.82424621,\n",
              "       0.94676573, 0.77282801, 0.8027807 , 0.81881559, 0.57605496,\n",
              "       0.66418492, 0.81123181, 0.4847865 , 0.77518523, 0.87061184,\n",
              "       0.89298044, 0.7002728 , 0.90532349, 0.47955903, 0.73890533,\n",
              "       0.48627451, 0.        , 0.56848433, 0.17040359, 0.1957905 ,\n",
              "       0.15189873, 0.        , 0.        , 0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ER-ptjNfoqb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4b7ab5bd-fe44-4e0f-f991-34fc7924e2df"
      },
      "source": [
        "# F1 score\n",
        "df = pd.DataFrame(f1_score(val_tags_l, y_predicted_l,average=None,labels=f_label), index = f_label).round(2)\n",
        "df.sort_values(by=0,ascending=False).transpose()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>-</th>\n",
              "      <th>NUM_B</th>\n",
              "      <th>DAT_B</th>\n",
              "      <th>DAT_I</th>\n",
              "      <th>TIM_I</th>\n",
              "      <th>PER_B</th>\n",
              "      <th>TIM_B</th>\n",
              "      <th>ORG_B</th>\n",
              "      <th>CVL_B</th>\n",
              "      <th>TRM_B</th>\n",
              "      <th>PER_I</th>\n",
              "      <th>EVT_B</th>\n",
              "      <th>NUM_I</th>\n",
              "      <th>LOC_B</th>\n",
              "      <th>ORG_I</th>\n",
              "      <th>ANM_B</th>\n",
              "      <th>EVT_I</th>\n",
              "      <th>TRM_I</th>\n",
              "      <th>AFW_B</th>\n",
              "      <th>MAT_B</th>\n",
              "      <th>FLD_B</th>\n",
              "      <th>CVL_I</th>\n",
              "      <th>AFW_I</th>\n",
              "      <th>LOC_I</th>\n",
              "      <th>PLT_B</th>\n",
              "      <th>MAT_I</th>\n",
              "      <th>FLD_I</th>\n",
              "      <th>ANM_I</th>\n",
              "      <th>PLT_I</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      -  NUM_B  DAT_B  DAT_I  TIM_I  ...  PLT_B  MAT_I  FLD_I  ANM_I  PLT_I\n",
              "0  0.96   0.95   0.93   0.91   0.89  ...   0.15    0.0    0.0    0.0    0.0\n",
              "\n",
              "[1 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oQtN5Pcdoqb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "fc602a9d-5347-4a34-945b-76a3d20eb41d"
      },
      "source": [
        "# Recall\n",
        "df = pd.DataFrame(recall_score(val_tags_l, y_predicted_l,average=None,labels=f_label), index = f_label).round(2)\n",
        "df.sort_values(by=0,ascending=False).transpose()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>-</th>\n",
              "      <th>NUM_B</th>\n",
              "      <th>DAT_I</th>\n",
              "      <th>DAT_B</th>\n",
              "      <th>LOC_B</th>\n",
              "      <th>PER_B</th>\n",
              "      <th>TIM_I</th>\n",
              "      <th>ORG_B</th>\n",
              "      <th>TIM_B</th>\n",
              "      <th>NUM_I</th>\n",
              "      <th>CVL_B</th>\n",
              "      <th>PER_I</th>\n",
              "      <th>EVT_B</th>\n",
              "      <th>TRM_B</th>\n",
              "      <th>ORG_I</th>\n",
              "      <th>ANM_B</th>\n",
              "      <th>EVT_I</th>\n",
              "      <th>TRM_I</th>\n",
              "      <th>AFW_B</th>\n",
              "      <th>FLD_B</th>\n",
              "      <th>CVL_I</th>\n",
              "      <th>MAT_B</th>\n",
              "      <th>AFW_I</th>\n",
              "      <th>PLT_B</th>\n",
              "      <th>MAT_I</th>\n",
              "      <th>LOC_I</th>\n",
              "      <th>FLD_I</th>\n",
              "      <th>ANM_I</th>\n",
              "      <th>PLT_I</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      -  NUM_B  DAT_I  DAT_B  LOC_B  ...  MAT_I  LOC_I  FLD_I  ANM_I  PLT_I\n",
              "0  0.96   0.96   0.95   0.93   0.91  ...    0.0    0.0    0.0    0.0    0.0\n",
              "\n",
              "[1 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL__hW33TxEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Precision\n",
        "df = pd.DataFrame(precision_score(val_tags_l, y_predicted_l,average=None,labels=f_label), index = f_label).round(2)\n",
        "df.sort_values(by=0,ascending=False).transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8nlAYCBslLx",
        "colab_type": "text"
      },
      "source": [
        "# ● inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQrsaVT5ypu3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "d93edade-fe96-4175-a4f2-e9c9c2731217"
      },
      "source": [
        "context = pd.read_table(\"/content/drive/My Drive/projects/04강 고려의 발전과 변화.txt\", header=None)\n",
        "context"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>안녕하세요, 여러분. 역사는 최태성! 빵! 지금 수능특강을 열심히 열심히 달리고 있...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>우리가 드디어 중세 와우! 70만 년 역사 끝냈고 천 년의 고대 끝냈고 이제 중세 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>고려 오백 년이고요. 그다음이 조선 오백 년. 이렇게 합쳐서 천 년이 있어요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>그중에서 중세 고려 오백여 년의, 그 오백 년 조금 안 되겠구나. 역사를 한번 살펴...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>앞에서 한번 설명드렸지만 고려는 호족의 시대입니다. 호족이 나라를 세웠죠. 대표적인...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>호족의 시대, 문벌귀족의 시대, 무신의 시대, 권문세족의 시대, 신진사대부의 시대....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>외침에 맞서 싸웠던 거란, 여진, 몽골, 홍건적과 왜구에 맞서 싸웠던 그런 역사. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>비록 충 자가 들어가고 부마국이 되었지만, 그래도 우리의 자주성을 잃지는 않았다는 사실.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>이걸 여러분들이 고려인들을 통해서 배우면 어떨까 하는 생각이 듭니다. 그런 DNA를...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>자랑스러운 고려의 역사였습니다. 고려의 역사 공부했으니까요. 지금부터 별채우기 시작...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>254 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     0\n",
              "0    안녕하세요, 여러분. 역사는 최태성! 빵! 지금 수능특강을 열심히 열심히 달리고 있...\n",
              "1    우리가 드디어 중세 와우! 70만 년 역사 끝냈고 천 년의 고대 끝냈고 이제 중세 ...\n",
              "2          고려 오백 년이고요. 그다음이 조선 오백 년. 이렇게 합쳐서 천 년이 있어요.\n",
              "3    그중에서 중세 고려 오백여 년의, 그 오백 년 조금 안 되겠구나. 역사를 한번 살펴...\n",
              "4    앞에서 한번 설명드렸지만 고려는 호족의 시대입니다. 호족이 나라를 세웠죠. 대표적인...\n",
              "..                                                 ...\n",
              "249  호족의 시대, 문벌귀족의 시대, 무신의 시대, 권문세족의 시대, 신진사대부의 시대....\n",
              "250  외침에 맞서 싸웠던 거란, 여진, 몽골, 홍건적과 왜구에 맞서 싸웠던 그런 역사. ...\n",
              "251  비록 충 자가 들어가고 부마국이 되었지만, 그래도 우리의 자주성을 잃지는 않았다는 사실.\n",
              "252  이걸 여러분들이 고려인들을 통해서 배우면 어떨까 하는 생각이 듭니다. 그런 DNA를...\n",
              "253  자랑스러운 고려의 역사였습니다. 고려의 역사 공부했으니까요. 지금부터 별채우기 시작...\n",
              "\n",
              "[254 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlDsz4-w-F4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.to('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQCCViSNsm7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ner_inference(test_sentence):\n",
        "    tokenized_sentence = torch.tensor([tokenizer.encode(test_sentence,truncation=True, max_length=max_len, pad_to_max_length=True)])\n",
        "    ans = model.forward(tokenized_sentence,real_tags=None)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(tokenized_sentence[0])\n",
        "\n",
        "    new_tokens, new_labels = [], []\n",
        "    for token, label_idx in zip(tokens, ans[0]):\n",
        "\n",
        "        if token.startswith(\"▁\"):\n",
        "            new_labels.append(label_to_tag[label_idx])\n",
        "            new_tokens.append(token[1:])\n",
        "        elif token not in ['[CLS]', '[SEP]', '[PAD]']:\n",
        "            new_tokens[-1] = new_tokens[-1] + token\n",
        "\n",
        "    for token, label in zip(new_tokens, new_labels):\n",
        "        print(\"{}\\t{}\".format(label, token))"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AP7YKMlsnnZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "03e9d361-fcb7-4697-e6f9-41c1643e513e"
      },
      "source": [
        "ner_inference(context.iloc[13,0])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\t그\n",
            "-\t새로운\n",
            "-\t세력들이\n",
            "-\t누구냐면,\n",
            "LOC_B\t향리\n",
            "-\t출신의\n",
            "-\t성리학을\n",
            "-\t수용한\n",
            "ORG_B\t신진사대부들.\n",
            "-\t그\n",
            "-\t신진사대부들이\n",
            "CVL_B\t권문세족을\n",
            "-\t공격하면서\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUKxiYRYsqkb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "ef2c3930-fccb-4703-d0c7-6651d766a672"
      },
      "source": [
        "ner_inference(context.iloc[48,0])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\t어떤\n",
            "-\t걸\n",
            "-\t했냐면\n",
            "-\t먼저\n",
            "TRM_B\t노비안검법이라는\n",
            "-\t걸\n",
            "-\t시행합니다.\n",
            "-\t왜냐면\n",
            "CVL_B\t호족들이\n",
            "-\t노비를\n",
            "-\t많이\n",
            "-\t갖고\n",
            "-\t있었거든요.\n",
            "-\t노비는\n",
            "-\t뭐예요?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGML4-9YRwIV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "defc70ca-15ad-4889-9f64-b94a4bc31ede"
      },
      "source": [
        "ner_inference(context.iloc[163,0])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PER_B\t충선왕,\n",
            "PER_B\t충렬왕,\n",
            "PER_B\t충목왕,\n",
            "PER_B\t충숙왕.\n",
            "-\t이런\n",
            "-\t식으로\n",
            "-\t충\n",
            "-\t자가\n",
            "-\t들어가요.\n",
            "-\t특히\n",
            "LOC_B\t몽골의\n",
            "CVL_B\t공주와\n",
            "-\t결혼을\n",
            "-\t해야\n",
            "-\t돼요.\n",
            "-\t그래서\n",
            "LOC_B\t부마국.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcN84vrlRxSE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "6a5c4826-8813-4a55-b42c-82bbf387717e"
      },
      "source": [
        "ner_inference(context.iloc[170,0])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ORG_B\t쌍성총관부를\n",
            "-\t가져갑니다.\n",
            "LOC_B\t철령\n",
            "LOC_B\t이북\n",
            "-\t지역이거든요.\n",
            "-\t이\n",
            "-\t지역을\n",
            "-\t가져가는\n",
            "-\t모습들\n",
            "-\t보이고\n",
            "-\t있고요.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHWWmlx_zQkJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "07700363-c370-479e-a4de-1c2558436edf"
      },
      "source": [
        "ner_inference(context.iloc[179,0])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PER_B\t공민왕의\n",
            "-\t어떤\n",
            "-\t반원\n",
            "-\t자주\n",
            "-\t정책.\n",
            "-\t이걸\n",
            "-\t다\n",
            "-\t부정합니다.\n",
            "ORG_B\t쌍성총관부\n",
            "-\t없애고요.\n",
            "LOC_B\t정동행성\n",
            "LOC_B\t이문소\n",
            "-\t없애고요.\n",
            "-\t정방\n",
            "-\t없애고요.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-52EBaBEzib4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "a8e7ed28-da07-4e23-814e-043b5826a80b"
      },
      "source": [
        "ner_inference(context.iloc[245,0])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FLD_B\t성리학을\n",
            "-\t장착했던\n",
            "PER_B\t신진사대부가\n",
            "-\t딱\n",
            "ANM_B\t손을\n",
            "-\t잡고\n",
            "PER_B\t이성계는\n",
            "-\t당시\n",
            "LOC_B\t왜구,\n",
            "PER_B\t홍건적을\n",
            "-\t물리치면서\n",
            "CVL_B\t슈퍼스타가\n",
            "-\t되는\n",
            "-\t거야.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4wc_6tv-NxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}